---
layout: about
title: home
permalink: /
subtitle: Security, Privacy, Usability and Design 
nav: false  # Add this line to include the page in navigation
# nav_order: 1  # Add this line to control the order in navigation (optional)


profile:
  align: right
  image: spud_lab_logo.png
  image_circular: false # crops the image to make it circular
  more_info:
    HCII, Carnegie Mellon University
    Pittsburgh, Pennsylvania, 15217
    <a href="mailto:spudlab@cmu.edu">spudlab@cmu.edu</a>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---

<b>How might we build systems that empower people with greater agency over their personal data?</b>
We tackle this critical question in today's digital world. Our interdisciplinary approach combines Human-Computer Interaction, Security and Privacy, and Applied AI to create solutions that encourage better security behaviors. We focus on three key areas: designing systems that resonate with human motivations, holding data harvesters accountable, and helping practitioners balance utility with privacy. As computing encompasses more of our lives, our goal is to empower end-users with novel security and privacy systems that connect core human drives with desired security outcomes. We create systems that mitigate pain, social rejection, and fear while enhancing feelings of hope, social acceptance, and pleasure. Ultimately, the SPUD Lab aims to design user-friendly systems that make better security and privacy behaviors not just possible, but natural and rewarding.

<!-- We focus on addressing a critical question in today's digital landscape: How might we build systems that empower people with greater agency over their personal data? Our research group draws on our core competencies at the intersection of Human-Computer Interaction, Security and Privacy, and Applied Artificial Intelligence. Our work tackles three unique interrelated challenges. 1. The Human Factors Challenge - we explore how to design systems that make it easier for users to resist intrusive data collection. 2. The Power Challenge - we investigate ways to hold data harvesters accountable to the people whose data they collect. 3. The Design Challenge - we aim to help practitioners better balance the utility and intrusiveness of novel technology concepts. Through these efforts, we strive to redistribute power and privacy in digital systems, addressing the discrepancy between people's concerns about online privacy and their feelings of powerlessness to effect change. -->

<!-- Security and privacy help realize the full potential of computing in society. Without authentication and encryption, for example, few would use digital wallets, social media or even e-mail. The struggle of security and privacy is to realize this potential without imposing too steep a cost. 

Yet, for the average non-expert, security and privacy are just that: costly, in terms of things like time, attention and social capital. More specifically, security and privacy tools are misaligned with core human drives: a pursuit of pleasure, social acceptance and hope, and a repudiation of pain, social rejection and fear. It is unsurprising, therefore, that for many people, security and privacy tools are begrudgingly tolerated if not altogether subverted. This cannot continue. As computing encompasses more of our lives, we are tasked with making increasingly more security and privacy decisions. 

Simultaneously, the cost of every breach is swelling. Today, a security breach might compromise sensitive data about our finances and schedules as well as deeply personal data about our health, communications, and interests. Tomorrow, as we enter the era of pervasive smart things, that breach might compromise access to our homes, vehicles and bodies.

We aim to empower end-users with novel security and privacy systems that connect core human drives with desired security outcomes. We do so by creating systems that mitigate pain, social rejection and fear, and that enhance feelings of hope, social acceptance and pleasure. Ultimately, the goal of the SPUD Lab is to design new, more user-friendly systems that encourage better end-user security and privacy behaviors. -->
